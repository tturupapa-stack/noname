# 캐싱 레이어 구현 요구사항

## [기능명]
Redis/메모리 캐시를 통한 API 응답 속도 개선 시스템

## [기능 설명]

### 목적
- **외부 API 호출 비용 감소**: Yahoo Finance API, Exa 뉴스 API 등 외부 API 호출 횟수 최소화
- **응답 속도 개선**: 캐시 히트 시 평균 응답 시간 90% 이상 단축 (예: 2-3초 → 50-100ms)
- **서버 부하 감소**: 동일한 요청에 대한 중복 처리를 방지하여 CPU/네트워크 리소스 절약
- **확장성 확보**: 분산 환경에서도 동일한 캐시를 공유할 수 있도록 Redis 지원
- **개발/프로덕션 환경 유연성**: 개발 환경에서는 메모리 캐시, 프로덕션에서는 Redis 선택 가능

### 사용 시나리오
1. **종목 조회 API** (`GET /api/stocks/{ticker}`)
   - 사용자가 같은 종목을 반복 조회할 때 캐시에서 즉시 반환
   - 초기 요청 시에만 Yahoo Finance API 호출 후 결과 캐싱

2. **화제 종목 조회 API** (`GET /api/stocks/trending`)
   - 5분간 동일한 화제 종목 정보 반환
   - 같은 시간대의 여러 사용자가 동일한 캐시된 결과 공유

3. **차트 데이터 조회 API** (`GET /api/stocks/{ticker}/chart`)
   - 과거 데이터는 자주 변하지 않으므로 긴 TTL 적용
   - 같은 기간의 차트 데이터는 캐시에서 제공

4. **TOP N 종목 조회 API** (`GET /api/stocks/trending/top`)
   - 동일한 조건(type, count)으로 조회 시 캐시 활용
   - 실시간성이 중요하지 않은 데이터는 캐시 우선 조회

5. **브리핑 조회 API** (`GET /api/briefings`)
   - 생성된 브리핑은 불변 데이터이므로 장기 캐싱
   - 페이지네이션된 결과도 캐싱하여 반복 조회 시 성능 향상

## [요구사항]

### 1. 엔드포인트

#### 1.1 캐시 관리 엔드포인트
- **캐시 초기화**: `POST /api/cache/clear`
  - 전체 캐시 삭제 (기존 `/api/stocks/cache/clear` 확장)
- **특정 키 캐시 삭제**: `DELETE /api/cache/{key_pattern}`
  - 특정 패턴의 캐시 키 삭제 (예: 특정 종목의 모든 캐시)
- **캐시 통계 조회**: `GET /api/cache/stats`
  - 캐시 히트율, 미스율, 키 개수, 메모리 사용량 등

### 2. Request

#### 2.1 캐시 초기화
```http
POST /api/cache/clear
Authorization: Bearer {API_KEY}
Content-Type: application/json
```

**요청 본문 (선택사항)**:
```json
{
  "pattern": "stock_detail_*",  // 특정 패턴만 삭제 (옵션)
  "all": false                   // 전체 삭제 여부
}
```

#### 2.2 캐시 통계 조회
```http
GET /api/cache/stats
Authorization: Bearer {API_KEY}
```

### 3. Response

#### 3.1 캐시 초기화 응답
```json
{
  "success": true,
  "data": {
    "deleted_keys": 42,
    "message": "캐시가 초기화되었습니다"
  }
}
```

#### 3.2 캐시 통계 응답
```json
{
  "success": true,
  "data": {
    "cache_type": "redis",  // "redis" 또는 "memory"
    "total_keys": 1250,
    "hit_rate": 0.87,        // 히트율 (0~1)
    "miss_rate": 0.13,       // 미스율 (0~1)
    "memory_usage": {
      "used_mb": 45.2,
      "max_mb": 512.0
    },
    "ttl_stats": {
      "trending": 300,
      "stock_detail": 300,
      "chart": 300,
      "news": 900
    }
  }
}
```

### 4. 추가 요구사항

#### 4.1 레이어드 캐싱 전략
- **1차 캐시 (L1)**: 인메모리 캐시 (빠른 접근)
  - 자주 조회되는 데이터 우선 저장
  - TTL이 짧은 데이터 (5분 이하)
- **2차 캐시 (L2)**: Redis 캐시 (분산 환경 지원)
  - 모든 API 응답 저장
  - 긴 TTL 데이터도 저장 가능
  - 멀티 인스턴스 환경에서 캐시 공유

#### 4.2 캐시 키 전략
- **네임스페이스**: `{service}:{resource}:{identifier}:{params}`
  - 예: `stocks:detail:AAPL`, `stocks:chart:TSLA:5d`, `briefings:list:page1:limit10`
- **일관성**: 동일한 데이터는 동일한 키로 접근
- **버전 관리**: 필요시 키에 버전 포함 (`v1:stocks:detail:AAPL`)

#### 4.3 TTL (Time To Live) 설정
- **화제 종목**: 300초 (5분) - 시장 변동성이 높음
- **종목 상세**: 300초 (5분) - 가격 변동 반영 필요
- **차트 데이터**: 
  - 5d: 300초 (5분)
  - 1mo, 3mo, 6mo: 1800초 (30분) - 과거 데이터는 변동 적음
  - 1y: 3600초 (1시간)
- **뉴스**: 900초 (15분) - 뉴스는 자주 업데이트되지 않음
- **브리핑 목록**: 600초 (10분) - 생성된 브리핑은 불변
- **브리핑 상세**: 3600초 (1시간) - 완전히 불변 데이터

#### 4.4 캐시 무효화 (Cache Invalidation)
- **자동 만료**: TTL 기반 자동 삭제
- **수동 삭제**: 관리자 API를 통한 특정 키 삭제
- **태그 기반 삭제**: 특정 종목 관련 모든 캐시 삭제 (예: `stocks:*:AAPL:*`)
- **이벤트 기반 무효화**: 새로운 브리핑 생성 시 관련 캐시 무효화

#### 4.5 환경별 설정
- **개발 환경**: 
  - 메모리 캐시만 사용 (Redis 없이 빠른 개발)
  - 환경 변수로 활성화/비활성화 가능
- **프로덕션 환경**:
  - Redis 우선, 실패 시 메모리 캐시로 폴백
  - Redis 연결 풀링 및 재연결 로직

## [기술적 고려사항]

### 에러 처리

#### Redis 연결 실패 시
- **폴백 전략**: Redis 연결 실패 시 자동으로 인메모리 캐시로 전환
- **로그 기록**: 연결 실패 시 경고 로그 기록하되 서비스는 계속 운영
- **재연결 로직**: 주기적으로 Redis 연결 시도 (exponential backoff)

#### 캐시 조회 실패 시
- **Graceful Degradation**: 캐시 조회 실패 시 원본 API 호출로 진행
- **에러 응답 금지**: 캐시 오류로 인해 전체 요청이 실패하지 않도록 보장
- **모니터링**: 캐시 오류율 추적 및 알림

#### 직렬화 오류
- **안전한 직렬화**: Pydantic 모델을 JSON으로 안전하게 변환
- **타입 검증**: 캐시에서 조회한 데이터의 타입 검증
- **오류 복구**: 직렬화 오류 시 해당 캐시 키 삭제 후 재생성

### 유효성 검증

#### 캐시 키 유효성
- **키 형식 검증**: 올바른 네임스페이스와 형식 사용 확인
- **키 길이 제한**: Redis 키 길이 제한 준수 (512MB 권장, 실용적으로는 1024바이트 이하)
- **특수문자 처리**: URL 인코딩 등으로 특수문자 안전하게 처리

#### 캐시 값 유효성
- **데이터 타입 검증**: 저장 전 Pydantic 모델로 검증
- **크기 제한**: 개별 캐시 값 크기 제한 (예: 10MB)
- **TTL 범위 검증**: TTL이 합리적인 범위 내인지 확인 (1초 ~ 7일)

#### 입력 검증
- **캐시 삭제 패턴**: SQL Injection과 유사한 패턴 공격 방지
- **권한 검증**: 캐시 관리 API는 인증된 사용자만 접근 가능

### 성능 최적화

#### Redis 최적화
- **Connection Pooling**: 연결 풀 사용으로 연결 오버헤드 감소
- **파이프라인**: 여러 명령을 파이프라인으로 묶어 네트워크 왕복 감소
- **압축**: 큰 데이터는 gzip 압축 후 저장 (예: 차트 데이터)
- **인코딩**: UTF-8 인코딩 사용, 바이너리 데이터는 base64 인코딩

#### 메모리 캐시 최적화
- **LRU Eviction**: 메모리 부족 시 가장 오래 사용되지 않은 항목 제거
- **크기 제한**: 메모리 사용량이 특정 임계값 초과 시 자동 정리
- **백그라운드 정리**: 만료된 항목을 주기적으로 백그라운드에서 정리

#### 캐시 워밍업 (Cache Warming)
- **서버 시작 시**: 자주 조회되는 데이터를 미리 캐싱
- **스케줄링**: 특정 시간에 자주 조회될 것으로 예상되는 데이터 사전 캐싱
- **예측 로딩**: 사용자 행동 패턴 기반 예측 캐싱

#### 모니터링 및 메트릭
- **히트율 모니터링**: 캐시 히트/미스 비율 추적 (목표: 70% 이상)
- **응답 시간 측정**: 캐시 히트 vs 미스 시 응답 시간 비교
- **메모리 사용량**: Redis와 메모리 캐시의 메모리 사용량 모니터링
- **캐시 크기**: 키 개수와 평균 값 크기 추적

### 추가 고려사항

#### 동시성 제어
- **Cache Stampede 방지**: 동일 키에 대한 동시 요청 시 한 번만 실제 API 호출
  - Redis 분산 락 또는 메모리 레벨 락 사용
- **낙관적 락**: 캐시 업데이트 시 충돌 방지

#### 데이터 일관성
- **Read-Through**: 캐시 미스 시 원본에서 로드 후 캐시 저장
- **Write-Through**: 데이터 업데이트 시 캐시와 원본 동시 업데이트 (필요시)
- **Write-Behind**: 비동기로 캐시 업데이트 (선택적)

#### 보안
- **캐시 데이터 암호화**: 민감한 데이터는 암호화 후 저장 (선택적)
- **접근 제어**: Redis 인증 및 네트워크 분리
- **캐시 포이즈닝 방지**: 사용자 입력으로 캐시 키 생성 시 검증 필수

#### 확장성
- **캐시 분할**: 데이터 타입별로 다른 Redis 인스턴스 사용 가능
- **지역별 캐싱**: 지역별로 다른 TTL 적용 가능
- **CDN 통합**: 정적 데이터는 CDN과 연동 가능하도록 설계

