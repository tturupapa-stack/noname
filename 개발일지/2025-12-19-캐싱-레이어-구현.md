# 개발일지 - 캐싱 레이어 구현

**작성 시각**: 2025-12-19 23:35

## 해결하고자 한 문제

외부 API 호출 비용 감소 및 응답 속도 개선을 위한 레이어드 캐싱 시스템 구현

### 요구사항
1. L1 (메모리) + L2 (Redis) 레이어드 캐싱
2. 캐시 관리 API (통계, 초기화, 삭제)
3. 가변 TTL (데이터 타입별)
4. 히트율 모니터링 (목표 70%)
5. Redis 연결 실패 시 메모리 폴백

## 해결된 것

### 1. 캐시 서비스 재작성 (`cache_service.py`)

✅ **MemoryCache 클래스**
- LRU (Least Recently Used) 정책
- 최대 엔트리 수 제한 (기본 1000개)
- 메모리 크기 제한 (기본 100MB)
- 통계 추적 (hits, misses, sets, deletes, errors)

✅ **RedisCache 클래스**
- 비동기 Redis 클라이언트 (redis-py async)
- 연결 풀링
- Exponential backoff 재연결
- 연결 실패 시 graceful degradation

✅ **CacheManager 클래스**
- L1 + L2 통합 인터페이스
- 동기/비동기 메서드 모두 지원 (기존 코드 호환)
- Stampede 방지 (asyncio.Lock)
- 통계 및 헬스 체크

### 2. 캐시 관리 API (`/api/cache`)

✅ **새 엔드포인트**
- `GET /api/cache/stats` - 캐시 통계 (히트율, 키 수, 메모리)
- `GET /api/cache/health` - 헬스 체크 (L1/L2 상태)
- `GET /api/cache/keys` - 키 목록 조회
- `GET /api/cache/ttl` - TTL 설정 조회
- `POST /api/cache/clear` - 캐시 초기화 (패턴 지원)
- `DELETE /api/cache/{pattern}` - 패턴 삭제

### 3. 가변 TTL 설정

✅ **CacheTTL 클래스**
| 데이터 타입 | TTL | 설명 |
|------------|-----|------|
| 화제 종목 | 300초 | 5분 |
| 종목 상세 | 300초 | 5분 |
| 뉴스 | 900초 | 15분 |
| 차트 5일 | 300초 | 5분 |
| 차트 1개월 | 1800초 | 30분 |
| 차트 3개월+ | 3600초 | 1시간 |
| 브리핑 상세 | 3600초 | 1시간 |
| 브리핑 목록 | 600초 | 10분 |

### 4. 환경 설정

✅ **config.py 및 .env.example**
```env
CACHE_BACKEND=memory  # memory | redis | layered
CACHE_REDIS_URL=redis://localhost:6379/0
CACHE_L1_MAX_ENTRIES=1000
CACHE_L1_MAX_MEMORY_MB=100
```

### 5. 테스트 결과

✅ **API 테스트**
- 캐시 헬스: `healthy` (L1 정상)
- 캐시 히트 응답 시간: ~10ms
- 패턴 삭제: `news_*` 3개 키 삭제 성공
- 프리로딩: TOP 3 종목 자동 캐싱

## 해결되지 않은 것 / 향후 개선 필요

⚠️ **Redis 테스트**
- 로컬에 Redis 미설치로 L2 캐시 미테스트
- 프로덕션 환경에서 Redis 연결 테스트 필요

⚠️ **히트율 최적화**
- 현재 초기 히트율 16.67% (프리로딩 직후)
- 실제 사용 패턴에서 70% 이상 달성 필요

⚠️ **캐시 워밍업 개선**
- 현재: 서버 시작 시 TOP 3 종목만 프리로드
- 향후: 인기 종목 예측 기반 프리로드 고려

## 기술적 세부사항

### 사용한 기술
- **redis-py 5.0+**: 비동기 Redis 클라이언트
- **pydantic-settings**: 환경 변수 기반 설정
- **OrderedDict**: LRU 캐시 구현
- **asyncio.Lock**: Stampede 방지

### 아키텍처
```
API → CacheManager
         ├── L1 (MemoryCache) → ~1ms
         └── L2 (RedisCache) → ~5-10ms (미사용 시 폴백)
```

### 주요 코드 패턴

**기존 코드 호환성**
```python
# 기존 코드 그대로 동작
cache.get(key)
cache.set(key, value, ttl)

# 새 비동기 코드
await cache_manager.aget(key)
await cache_manager.aset(key, value, ttl)
```

**Stampede 방지**
```python
async def get_or_set(key, factory, ttl):
    async with self._locks[key]:
        value = await self.aget(key)
        if value is None:
            value = await factory()
            await self.aset(key, value, ttl)
        return value
```

## 향후 개발을 위한 컨텍스트

### 파일 구조
```
backend/
├── config.py           # 환경 설정 (신규)
├── main.py             # 캐시 라우터 등록 (수정)
├── api/
│   └── cache.py        # 캐시 관리 API (신규)
├── models/
│   └── cache.py        # 캐시 응답 모델 (신규)
└── services/
    └── cache_service.py # 캐시 서비스 (전면 재작성)
```

### Redis 활성화 방법
1. `.env` 파일에 `CACHE_BACKEND=layered` 설정
2. Redis 서버 실행 (`redis-server`)
3. 서버 재시작

### 확장 가능성
- Redis Cluster 지원 (현재 단일 인스턴스)
- 캐시 압축 (gzip)
- 분산 락 (Redis 기반)
- 캐시 이벤트 훅 (무효화 이벤트)
